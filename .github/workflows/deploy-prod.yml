name: Deploy Production

on:
  push:
    branches:
      - master

jobs:
  deploy:
    name: Deploy to Zyte production project
    runs-on: ubuntu-latest
    env:
      SHUB_APIKEY: ${{ secrets.scrapycloud_api_key }}
      SHUB_PROJECTID: ${{ secrets.scrapycloud_project_id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install pipenv
        run: |
          python -m pip install --upgrade pip
          pip install pipenv

      - name: Cache pipenv virtualenv
        uses: actions/cache@v3
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}
          restore-keys: |
            ${{ runner.os }}-pipenv-

      - name: Install dependencies
        run: |
          pipenv install --dev

      - name: Install shub
        run: |
          pipenv run pip install shub

      - name: Deploy code to Scrapy Cloud
        run: |
          set -e
          exit_code=0
          
          for spider in $(ls locations/spiders/*.py); do
            echo "Deploying $spider..."
            pipenv run shub deploy ${SHUB_PROJECTID} --spider $spider --version "master-${GITHUB_SHA}" || exit_code=$?
            if [ $exit_code -ne 0 ]; then
              echo "::warning::Deployment failed for $spider but continuing with the next spider."
              exit_code=0  # Reset exit code to continue
            fi
          done
          
          if [ $exit_code -ne 0 ]; then
            echo "::error::One or more spiders failed to deploy. Check the logs for more details."
            exit $exit_code
          fi
        env:
          SHUB_APIKEY: ${{ secrets.scrapycloud_api_key }}
          SHUB_PROJECTID: ${{ secrets.scrapycloud_project_id }}
